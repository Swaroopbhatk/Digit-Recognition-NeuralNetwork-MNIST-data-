{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import model_selection as cv\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "import seaborn as sns\n",
    "import gzip\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "iris = pd.read_csv(\"iris.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "iris.loc[iris[\"species\"]==\"setosa\",\"species\"]=0\n",
    "iris.loc[iris[\"species\"]==\"versicolor\",\"species\"]=1\n",
    "iris.loc[iris[\"species\"]==\"virginica\",\"species\"]=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = cv.train_test_split(iris.iloc[:,1:4], iris.iloc[:,4], test_size=0.30, random_state=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train = x_train.as_matrix()\n",
    "x_test = x_test.as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_test = pd.get_dummies(y_test).as_matrix()\n",
    "y_train = pd.get_dummies(y_train).as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class NeuralNet():\n",
    "    def __init__(self, train, target, x_test, y_test, hidden_layers = 2, neu_hid_layer = 6, learning_rate=0.5, epoch=20000):\n",
    "        self.train = train # This is a training data set\n",
    "        self.target = target # This is target column that needs to be predicted\n",
    "        self.hidden_layers = hidden_layers \n",
    "        self.neu_hid_layer = neu_hid_layer \n",
    "        self.in_layer = train.shape[1] \n",
    "        self.op_ly = 3\n",
    "        self.learning_rate = learning_rate \n",
    "        self.epoch = epoch\n",
    "        self.x_test = x_test\n",
    "        self.y_test = y_test\n",
    "        self.predicted = None\n",
    "        self.test_pred = None\n",
    "        self.sig = []\n",
    "        self.sig_der = []\n",
    "        self.zvalue = []\n",
    "        \n",
    "        if self.hidden_layers == 1:\n",
    "        # Initializing Random Weights\n",
    "            self.wt_ly1 = np.random.randn(self.in_layer, self.neu_hid_layer)\n",
    "            self.b_ly1 = np.ones((1, self.neu_hid_layer))\n",
    "            self.wt_ly2 = np.random.randn(self.neu_hid_layer, self.op_ly)\n",
    "            self.b_ly2 = np.ones((1, self.op_ly))\n",
    "        \n",
    "        elif self.hidden_layers == 2:\n",
    "            self.wt_ly1 = np.random.randn(self.in_layer, self.neu_hid_layer)\n",
    "            self.b_ly1 = np.ones((1, self.neu_hid_layer))\n",
    "            self.wt_ly2 = np.random.randn(self.neu_hid_layer, self.neu_hid_layer)\n",
    "            self.b_ly2 = np.ones((1, self.neu_hid_layer))\n",
    "            self.wt_ly3 = np.random.randn(self.neu_hid_layer, self.op_ly)\n",
    "            self.b_ly3 = np.ones((1, self.op_ly))\n",
    "            \n",
    "        \n",
    "    def activation(self, z):\n",
    "        return 1 / (1 + np.exp(-z))\n",
    "    \n",
    "    \n",
    "    def softmax(self, z):\n",
    "        scoreMatExp = np.exp(z)\n",
    "        return scoreMatExp / scoreMatExp.sum(0)\n",
    "    \n",
    "    \n",
    "    def gradient_descent(self, tdelta1, tdelta2, tb1, tb2, tdelta3=0, tb3=0): ## Need to see what can be done here\n",
    "        if self.hidden_layers == 1:\n",
    "            self.wt_ly1 = self.wt_ly1 - (self.learning_rate*tdelta1)\n",
    "            self.wt_ly2 = self.wt_ly2 - (self.learning_rate * tdelta2)\n",
    "            self.b_ly1 = self.b_ly1 - self.learning_rate*tb1\n",
    "            self.b_ly2 = self.b_ly2 - self.learning_rate*tb2\n",
    "        \n",
    "        elif self.hidden_layers == 2:\n",
    "            self.wt_ly1 = self.wt_ly1 - (self.learning_rate*tdelta1)\n",
    "            self.wt_ly2 = self.wt_ly2 - (self.learning_rate * tdelta2)\n",
    "            self.wt_ly3 = self.wt_ly3 - (self.learning_rate * tdelta3)\n",
    "            self.b_ly1 = self.b_ly1 - self.learning_rate*tb1\n",
    "            self.b_ly2 = self.b_ly2 - self.learning_rate*tb2\n",
    "            self.b_ly3 = self.b_ly3 - self.learning_rate*tb3\n",
    "    \n",
    "    def propogation(self, instance):\n",
    "        sig = []\n",
    "        sig_der = []\n",
    "        zvalue = []\n",
    "        if self.hidden_layers == 1:\n",
    "            # Forward Propogation\n",
    "            a1 = np.array(self.train)\n",
    "            z2 = np.dot(instance, self.wt_ly1)\n",
    "            a2 = self.activation(z2)\n",
    "            z3 = np.dot(a2, self.wt_ly2)\n",
    "            a3 = self.activation(z3)\n",
    "            error = a3 - inst.target\n",
    "           \n",
    "            sig.append(a3)\n",
    "            sig_der.append(a3*(1-a3))\n",
    "            zvalue.append(z3)\n",
    "            self.sig = sig\n",
    "            self.sig_der = sig_der\n",
    "            self.zvalue = zvalue\n",
    "        \n",
    "            #Backward Propogation to find derivative\n",
    "            delta2 = error * a3 * (1-a3)\n",
    "            delta1 = np.dot(delta2,  self.wt_ly2.T) * a2 * (1-a2) #a2*(1-a2) is derivative of sigmoid function\n",
    "            tdelta2 = np.dot(a2.T, delta2)\n",
    "            tdelta1 = np.dot(instance.T, delta1)\n",
    "            tb2 = np.sum(delta2, axis=0).reshape(np.shape(self.b_ly2))\n",
    "            tb1 = np.sum(delta1, axis=0).reshape(np.shape(self.b_ly1))\n",
    "\n",
    "            # adjust weights by gradient descent\n",
    "            self.gradient_descent(tdelta1, tdelta2, tb1, tb2)\n",
    "            \n",
    "            return a3, error\n",
    "        \n",
    "        elif self.hidden_layers == 2:\n",
    "            #Forward Propogation\n",
    "            a1 = np.array(self.train)\n",
    "            z2 = np.dot(instance, self.wt_ly1) + self.b_ly1\n",
    "            #print(z2.shape)\n",
    "            a2 = self.activation(z2)\n",
    "            z3 = np.dot(a2, self.wt_ly2) + self.b_ly2\n",
    "            #print(z3.shape)\n",
    "            a3 = self.activation(z3)\n",
    "            z4 = np.dot(a3, self.wt_ly3) + self.b_ly3\n",
    "            #print(z4.shape)\n",
    "            a4 = self.activation(z4)\n",
    "            #print(a4)\n",
    "            error = a4 - inst.target\n",
    "            \n",
    "            sig.append(a4)\n",
    "            sig_der.append(a4*(1-a4))\n",
    "            zvalue.append(z4)\n",
    "            self.sig = sig\n",
    "            self.sig_der = sig_der\n",
    "            self.zvalue = zvalue\n",
    "            \n",
    "            #Backward Propogation\n",
    "            delta3 = error * a4 * (1-a4)\n",
    "            #print(delta3.shape)\n",
    "            delta2 = np.dot(delta3, self.wt_ly3.T) * a3 * (1-a3)\n",
    "            #print(delta2.shape)\n",
    "            delta1 = np.dot(delta2,  self.wt_ly2.T) * a2 * (1-a2) #a2*(1-a2) is derivative of sigmoid function\n",
    "            #print(delta1.shape)\n",
    "            \n",
    "            tdelta3 = np.dot(a3.T, delta3)\n",
    "            #print(tdelta3.shape)\n",
    "            tdelta2 = np.dot(a2.T, delta2)\n",
    "            #print(tdelta2.shape)\n",
    "            tdelta1 = np.dot(instance.T, delta1)\n",
    "            #print(tdelta1.shape)\n",
    "            tb3 = np.sum(delta3, axis=0).reshape(np.shape(self.b_ly3))\n",
    "            #print(tb3.shape)\n",
    "            tb2 = np.sum(delta2, axis=0).reshape(np.shape(self.b_ly2))\n",
    "            #print(tb2.shape)\n",
    "            tb1 = np.sum(delta1, axis=0).reshape(np.shape(self.b_ly1))\n",
    "            #print(tb1.shape)\n",
    "            \n",
    "            # adjust weights by gradient descent\n",
    "            self.gradient_descent(tdelta1, tdelta2, tb1, tb2, tdelta3, tb3)\n",
    "            #print(a4)\n",
    "            #print(error)\n",
    "            return a4, error\n",
    " \n",
    "    def train_nn(self):\n",
    "        TRMSE = []\n",
    "        display = [2, 4, 5, 500, 1000, 2000, 3000, 4000, 5000, 5999]\n",
    "        for ep in range(self.epoch):\n",
    "            out, error = self.propogation(self.train)\n",
    "            self.predicted = out\n",
    "            #print(error)\n",
    "            RMSE = ((np.sum(error, axis=0) ** 2)**(1/2))/len(self.target)\n",
    "            #print(RMSE)\n",
    "            TRMSE.append(RMSE)\n",
    "            accuracy=1 - RMSE\n",
    "            if ep in display:\n",
    "                print(\"RMSE is:{0}, Accuracy is:  {1}, epoch is:{2}\".format(RMSE, accuracy, ep))\n",
    "            #break\n",
    "            \n",
    "        if self.hidden_layers == 1:\n",
    "            \n",
    "            result = {'Weigh1': self.wt_ly1, \n",
    "                      'Weight2':self.wt_ly2, \n",
    "                      'b1':self.b_ly1, \n",
    "                      'b2':self.b_ly2}\n",
    "            \n",
    "        elif self.hidden_layers == 2:\n",
    "            \n",
    "            result = {'Weigh1': self.wt_ly1, \n",
    "                      'Weight2':self.wt_ly2,\n",
    "                      'Weight3':self.wt_ly3,\n",
    "                      'b1':self.b_ly1, \n",
    "                      'b2':self.b_ly2,\n",
    "                      'b3': self.b_ly3}\n",
    "            \n",
    "        #print(\"'This is 3 layer Neural Network'\\n'Input Layer - 2'\\n'Hidden Layer - 1 (3 neurons)\\n'Output Layer - 1'\\n'Activation Function - Sigmoid'\")\n",
    "        print(result)\n",
    "        \n",
    "        return TRMSE\n",
    "\n",
    "\n",
    "    def predictClass(self):\n",
    "        if self.hidden_layers == 1:\n",
    "            # Feed Forward with suitable weights\n",
    "            a1 = np.array(self.x_test)\n",
    "            z2 = np.dot(a1, self.wt_ly1) + self.b_ly1\n",
    "            a2 = self.activation(z2)\n",
    "            z3 = np.dot(a2, self.wt_ly2) + self.b_ly2\n",
    "            a3 = self.activation(z3)\n",
    "            self.test_pred = np.round(a3)\n",
    "            \n",
    "        \n",
    "        elif self.hidden_layers == 2:\n",
    "            # Feed Forward with suitable weights\n",
    "            a1 = self.x_test\n",
    "            z2 = np.dot(a1, self.wt_ly1) + self.b_ly1\n",
    "            a2 = self.activation(z2)\n",
    "            z3 = np.dot(a2, self.wt_ly2) + self.b_ly2\n",
    "            a3 = self.activation(z3)\n",
    "            z4 = np.dot(a3, self.wt_ly3) + self.b_ly3\n",
    "            a4 = self.activation(z4)\n",
    "            #print(a4)\n",
    "            self.test_pred = np.round(a4)\n",
    "            #print(a2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE is:[ 0.34258939  0.2883504   0.34150916], Accuracy is:  [ 0.65741061  0.7116496   0.65849084], epoch is:2\n",
      "RMSE is:[ 0.34237813  0.09897402  0.34035835], Accuracy is:  [ 0.65762187  0.90102598  0.65964165], epoch is:4\n",
      "RMSE is:[ 0.3420766   0.29692895  0.3390689 ], Accuracy is:  [ 0.6579234   0.70307105  0.6609311 ], epoch is:5\n",
      "RMSE is:[ 0.00392615  0.07594231  0.07278955], Accuracy is:  [ 0.99607385  0.92405769  0.92721045], epoch is:500\n",
      "RMSE is:[ 0.00203059  0.07596314  0.07497317], Accuracy is:  [ 0.99796941  0.92403686  0.92502683], epoch is:1000\n",
      "RMSE is:[ 0.00224647  0.07534557  0.07208779], Accuracy is:  [ 0.99775353  0.92465443  0.92791221], epoch is:2000\n",
      "RMSE is:[ 0.00125033  0.07527939  0.07205149], Accuracy is:  [ 0.99874967  0.92472061  0.92794851], epoch is:3000\n",
      "RMSE is:[ 0.00180419  0.07503996  0.07209235], Accuracy is:  [ 0.99819581  0.92496004  0.92790765], epoch is:4000\n",
      "RMSE is:[ 0.00107145  0.07523478  0.07222028], Accuracy is:  [ 0.99892855  0.92476522  0.92777972], epoch is:5000\n",
      "RMSE is:[ 0.00093572  0.07536841  0.07645606], Accuracy is:  [ 0.99906428  0.92463159  0.92354394], epoch is:5999\n",
      "{'Weigh1': array([[-3.66794412,  1.51371598,  1.62073683, -4.40172309, -2.01331859,\n",
      "        -0.90481043],\n",
      "       [ 4.46789409,  1.55288763,  1.62485258,  5.82407648,  2.73616847,\n",
      "         1.63511782],\n",
      "       [ 1.60745299,  0.21809432,  0.08343426,  2.55675929,  2.88528218,\n",
      "         1.92047457]]), 'Weight2': array([[-8.60989841, -4.56973735, -5.95558751, -2.92413988, -2.29370685,\n",
      "        -0.32316851],\n",
      "       [ 1.58165055, -4.10140492, -3.42949688, -0.45174261, -1.35394937,\n",
      "        -0.45292175],\n",
      "       [ 0.99611697, -3.72956304, -0.40114083, -1.75428288, -0.24253029,\n",
      "        -1.46468197],\n",
      "       [-5.24856131, -8.0956715 , -3.83749644, -1.85269184, -5.04389886,\n",
      "        -0.77492186],\n",
      "       [-0.71188658, -2.61418259, -0.86473519, -1.76910743, -0.47159313,\n",
      "        -3.23323388],\n",
      "       [ 0.14609571, -2.38454902, -2.78178583, -1.60126746,  0.45614707,\n",
      "        -2.2546    ]]), 'Weight3': array([[ 12.52110495,  -6.88505575,  -6.65696946],\n",
      "       [  2.064932  ,  -0.88374825,  -2.70659244],\n",
      "       [  3.68581662,  -1.84878652,  -1.77128153],\n",
      "       [ -3.29686347,   1.21041553,  -3.54533522],\n",
      "       [  3.05647017,  -0.12794386,  -2.59995766],\n",
      "       [ -2.41555776,   1.3531993 ,  -1.85494874]]), 'b1': array([[-0.13480399,  0.9959798 ,  1.31490655,  0.14461847, -0.62367737,\n",
      "        -0.00901585]]), 'b2': array([[ 2.15311056, -2.0895211 ,  0.08920996, -0.90692044,  1.0549006 ,\n",
      "        -0.35580133]]), 'b3': array([[-6.68631321,  0.35783306, -0.35588018]])}\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAIABJREFUeJzt3XmcHHWd//HXe2ZyE+6gmATCERQw\nIBhRPPFawUXAFVb4qQsrLOrKeu+KP/whi7vrgaC7Ky6rrgKiAh4IuLigKLCoIAmCXIZEroSEkANy\nkWtmPr8/qrpT0+me7p7pmp6eej8fj0nqrk9Vdden6vut+rYiAjMzM4CudgdgZmajh5OCmZmVOSmY\nmVmZk4KZmZU5KZiZWZmTgpmZlTkpWMMkhaT92x1HMyQdJWlJpv8BSUe1MaSOJ+l9kr6S07KPkvRA\nq6dtJUlXSDpvhNd5naQ3j8S6CpUUJD0maaOk9Zm/r7Y7rqEYC9siaaqki9Jt2SDpCUk/lHREXuuM\niIMj4pbhLkfSeZKuqDNN6Ritk/SspN9Ier+kUfm9k3SapNvrTDMe+DRwgaTXZD57G9KLhuznca9m\nY4iIWyLi4FZP2yxJt0valG7HivRz+fw81tWgzwP/NBIrGpUfzpy9LSJ2yPydVW0iST2NDBtMs9MP\nQUPbMhpJmgD8EpgDHAvsCBwIXAm8tcY8ee/PPLwtIqYCe5N8sT8J/Fd7QxqW44E/RsSTEfG/pc8e\nUDo575z5PD6RnVFS12hNiDW8P922FwHTgC+1K5CI+A0wTdJhea+rkw5QrtKrpF9L+rKk1cB5NYZ1\nSfq0pMclPS3pckk7pcuYlV4tnS7pCZKTXuV6HpJ0bKa/R9JKSYdLmpjemq5KryzvkvS8YWzLv0ta\nI+mPkt6YGf+C9HZ0taRFkv4mM65b0v+V9Kf0Cne+pJmZxb9J0kJJz0i6WJKajS/1HmAGcEJE3B8R\nfRGxISJ+GBHnZeIJSR+UtBBYmA77V0mLJa1N43tNZvpJki5N43sQeFnFvnlM0pvS7i5JZ6fbukrS\n1ZJ2TceVjuWp6R3MSknnpOOOBv4v8M70SvLeehsbEWsi4jrgncCpkl6cLmuCpC+l61gu6RJJk9Jx\nu0v6afpZWC3pf0snVUkzJf04vYpdpcxdoqT3pp+zZyTdKGnviv35/spjKOlA4BLgyHSbnq2xKccA\nt9bb3sz6bpf0WUm/BTYAe0k6I41vXbrvz8hM/yZJj2X6l0j6mKT70s/y95VcUDQ1bTr+U5KekvSk\npL9J98WsetsQEauAHwMvzgzeVdLP0m34raR9Muv5ahrL2vQ7/MrMuFdIujsdt1zSBZlxr5J0R3q8\n75H02opQbqXGBVNLRURh/oDHgDfVGHca0Av8HdADTKox7L3AImBfYAeSD8t30mXMAgK4HJgCTKqy\nnnOB72b6/5zkygvgfcD1wGSgG3gpsOMwtuWjwDiSE9EaYNd0/K3A14CJwEuAFcAb03F/D9wHvBAQ\ncCiwWzougJ8COwN7pfMdPcRjcSVwaQPTBfBzYNfS/gTeDeyWHpOPA08BE9Nxnwf+N51+JnA/sKTa\nfgM+AtxBkpwmAP8JfL/iWH4jPe6HApuBA9Px5wFXDOXzBjwBfCDt/gpwXRrv1PT4fy4d9zmSE/W4\n9O816THpBu4Fvpx+ziYCr07nOYHk83lgun8+DfymYn9WPYbp5+b2Ott0F3BSleGl/dVTMfz2dD8c\nmG5DD/A2ku+PgDcAG4FD0unfBDyWmX9Jeoyenx7zh4EzhjDtscDSNI4pwPfTeGfV2M7bgdPS7mkk\n35lvp/1XACuBuek2XZX9LJBc8OyabusngSeBCZn9d0raPRV4edo9E1gFvIXkYv3odB27ZZb7D8DV\neZwbB2x73isYTX/ph3M98Gzm728yX4gnKqavNuxm4G8z/S8EtqYfgNIXY99BYtgfWAdMTvu/C5yb\ndr8X+E3pCzLMbVkKKDP979IP60ygD5iaGfc50hM0sAA4vsY6g/Tkk/ZfDZw9xGPxC+Dzmf6XpNuw\nFlhQsc431FnWM8ChafcjZBIVcCa1k8JDpMkw7d+zyrGcUbEPT067z2PoSeEO4BySk+IGYL/MuCOB\nR9Pu84Frgf0r5j+S5GTeU2XZPwNOz/R3Ac8Be9c7hjSWFBZS5UKAwZPCuXWW+VPgg2l3tRP9yZn+\ni4CvDmHay4HPZsa9iPpJ4bn0M/kk8B22XRxdAVySmfY44P4ayxHJ9/3gtP83JBeGu1VMdw5p0skM\nuxl4V6b/A8BNQ/m+NfNXxOKjEyJi58zfNzLjFleZvnLYC4DHM/2Pk5xEssU81ZYDQEQsIjkZvU3S\nZJIP1PfS0d8BbgSulLRU0hcljRvitjwZ6ScpE+cL0r/VEbGuYtz0tHsm8KdB1vlUpvs5krul7ah+\nheMqkpMwABFxT0TsDPwFyVV71oD9KenjafHDmrSYYydg93T0Cyqmzx6rSnsD16S368+SHJc+Bh7L\nhra3SdOB1SRXoJOB+ZkY/icdDnAByVX/TZIekXR2Onwm8HhE9NbYpn/NLG81yYlpemaa4WzTMyRX\nuM2oPH7HSrozLRJ7Fvgzth2/apqJt9a0lZ+Lmt/RjL9Nv1fTI+I9kRQj1Y1J0j8oKbJdQ7K/prBt\n+/4aOAhYIOl3kkrFQXsDp5SOW7pfXpHGXTKVJEnlqohJYTDVmoytHLaU5ACW7EVSVLO8znKyvg+c\nQlJp92CaKIiIrRHxjxFxEPBKklvev2o8/AGmSwPK+/dKY19KUh46tWLck2n3YmC/Ia6zLAZWgD9R\nZZKbgT+TNKWRxZU6lNQffBL4S2CXNJGsITnxASwjOWmWDPYEzGLgmIrEOjEinhxknu1iaoakl5Gc\noG8nKR7YSHIVWVr/TpFUbhIR6yLi4xGxL0mRy8eU1A0tJimbr1bxvhh4X8U2TYqkorIV2/QH4IAG\npqu63LS+5Ickd6fPS4/fTWw7fnlZRlJMWDKz1oTDIen1wMeAd5AU0e1CckcvgIhYEBEnA3sAFwI/\nkjSR5Lh9u+K4TYmICzKLP5Ck2DBXTgrN+z7wUUn7SNoB+BfgqhpXbbVcSXJ19AG23SUg6fWS5kjq\nJilG2Upy5ToUewAfkjRO0kkkH6gbImIxyS3s55RUbB8CnE5SjAXwTeCzkmanFZCHSNptiDEM5nKS\nL+o1kl6spIJ7Ikk57WCmkiThFUCPpHNJnlwquRr4lKRdJM0gqQ+q5RLgn5VWxEqaJun4BuNfDsxS\ng0/TSNpRyQMGV5IUO90XEf0kdRZflrRHOt10SW9Ju4+VtH+a3NeSfBb6SIqxlgGflzQlPY6vymzT\npyQdnC5jp/T4N7pNM5Q8dlrLDcDrGlxeNROA8STHry/dJ28cfJaWuBo4XdIL0zv0/5fTekqfz5Uk\n9Q3nkdwpACDpPZJ2T4/9GpKE2U9SSvB2SW8ufRfS80H2TuG1JMWDuSpiUri+omjjmibn/xbJAbwN\neBTYxOAnnu1ExDLgtyR3A1dlRj2f5CpqLUlRxq0k5Ze1DLYtdwKzST6c/wycmLn9PYWkDHgpcA3w\nmYj4eTruIpIv0E1pHP9FUtHaUhGxCXg98CDw3+m6FpA8LfSXg8x6I8kX42GSoqFNDCwK+Md0+KMk\n2/CdQZb1rySVvDdJWkdS1v/yBjfhB+n/qyTdPch016fLXkxSbnwRSRFCySdJiojukLSWpK7lhem4\n2Wn/epLPy9cieTa/j+TOYX+SSuslJA8TEBHXAF8gKYJcS1LRfkyD2/RL4AHgKUkra20P8KKKk1XD\nIuJZkgcgriEp2jqRpE4hVxFxPfAfJN/bhcCv01GbW7yqG0iO2UKSOqW1JAm85K3AQ+ln4kvAOyNi\nS0Q8BrydJFmtIDmuHyc9R0s6kqTYd7DPWktoYLGzjQWSTiN56uLV7Y7Fxh5JZwIHRcRH2h3LUEma\nA9xN8lRQf7vjqUfStcDFEXFT3uvqxJeBzKyNIuLr7Y5hKCS9neSudCrJo8vXdkJCAIiIRos1h62I\nxUdmVkwfJClOXUhS7PjB9oYzOrn4yMzMynynYGZmZR1Xp7D77rvHrFmz2h2GmVlHmT9//sqImFZv\nuo5LCrNmzWLevHntDsPMrKNIGuzt/jIXH5mZWZmTgpmZlTkpmJlZmZOCmZmVOSmYmVmZk4KZmZU5\nKZiZWVmhksJTazZx80PL609oZlZQhUoKb//arzn9Mr/4ZmZWS6GSwrI1m9odgpnZqFaopGBmZoNz\nUjAzszInBTMzK3NSMDOzMicFMzMrc1IwM7MyJwUzMytzUjAzszInBTMzKytkUoiIdodgZjYqFTIp\nmJlZdU4KZmZWVsik4NIjM7PqCpkUzMysOicFMzMryzUpSDpa0gJJiySdXWX8aZJWSLon/Tsjz3hK\nXHpkZlZdT14LltQNXAy8GVgC3CXpuoh4sGLSqyLirLziMDOzxuV5p3AEsCgiHomILcCVwPE5rs/M\nzIYpz6QwHVic6V+SDqv0Dkl/kPRDSTOrLUjSmZLmSZq3YsWKYQfml9fMzKrLMymoyrDKs/H1wKyI\nOAT4BXBZtQVFxNcjYm5EzJ02bdrQAxq/gvHT/sdJwcyshjyTwhIge+U/A1ianSAiVkXE5rT3G8BL\nc4yHyTO/zYTdb2HZhmV5rsbMrGPlmRTuAmZL2kfSeOBk4LrsBJL2zPQeBzyUYzygvtKKc12NmVmn\nyu3po4jolXQWcCPQDXwrIh6QdD4wLyKuAz4k6TigF1gNnJZXPHmLCDZs3cAO43dodyhmZkOW63sK\nEXFDRBwQEftFxD+nw85NEwIR8amIODgiDo2I10fEH/OMJ08/ePgHHPn9I3l87ePtDsXMbMgK+UZz\nHvXMtyy+BcBJwcw6WiGTgqo+GGVmZoVMCmZmVl0hk0K49SMzs6oKlhScDMzMBlOwpJCQ31MwM6uq\nkEnBrVyYmVVXyKRgZmbVFTIp9PXld6vgxvbMrJMVLCkkJ+xbHx5+89uVXE9hZmNBwZJCiU/gZmbV\nFDQpmJlZNYVMCi73NzOrrjBJYe2WtXSNWwf4FTYzs1oKkxS+cPul23rCdQpmZtUUJimsXL+l3O22\nj8zMqitMUsg+ceQqBTOz6gqTFEbqNQLfhZhZJytOUsjeKeS8fDOzTlWYpGBmZvUVJin4St7MrL7C\nJIUsVzSbmVVX0KTgrGBmVk0hk4IbxDMzq64wSSHbtLXvE8zMqitMUshy6ZGZWXWFSQoDnj7KMSu4\nvsLMOlmuSUHS0ZIWSFok6exBpjtRUkiam18s27ojh9eb/cirmY0FuSUFSd3AxcAxwEHAKZIOqjLd\nVOBDwJ15xZKuqdzli3kzs+ryvFM4AlgUEY9ExBbgSuD4KtN9FvgisCnHWHJv5sLMbCzIMylMBxZn\n+pekw8okHQbMjIifDrYgSWdKmidp3ooVK4Yd2FObHh72Miq5ITwzGwvyTArVCtnLZ05JXcCXgY/X\nW1BEfD0i5kbE3GnTpg0tmEw9wua+9UNaRrPrMTPrNHkmhSXAzEz/DGBppn8q8GLgFkmPAa8Arsuz\nstnMzAaXZ1K4C5gtaR9J44GTgetKIyNiTUTsHhGzImIWcAdwXETMyyMYv7xmZlZfbkkhInqBs4Ab\ngYeAqyPiAUnnSzour/W2m99TMLNO1pPnwiPiBuCGimHn1pj2qDxjyWa/PM7bfk/BzMaCwrzR/Fzf\nunK3r+XNzKorTFJYs/WpdodgZjbqFSYpDHh5zeX+ZmZVFScpaNum+kUzM7PqipMUXBFsZlZXcZKC\n3CCemVk9xUkKmU31PYOZWXWFSQpdmU3N807B9RVm1skKkxQGVjTnsYI8FmpmNrIKlBR81jYzq6cw\nSWFA8VEb4zAzG80KkxQG3Ck4K5iZVVWcpJAp9N/S/1wbIzEzG70KkxT6+7clhTtW/5BbH17Bc1t6\n2xiRmdnoU5ik0NO9rbuvPzj1W7/jjMty+T0fM7OOVZiksNtOW8vdu0wexzEvfj53P/FMy5a/eWs/\nkCQcM7NOVZikMHvn2eXunu4uZu+xA5vSE3krPLRsLQAPLF3TsmWamY20wiSFST2TB/SXnkZyM9pm\nZtsUJimM6x5X7o4ISk+oOieYmW1TmKTw4KoHBvR3le4U2hGMmdkoVZiksGz90kxflN9a6G/xrYKT\njJl1ssIkhcq2j1pffOS2lcys8xUnKVCZFErFR762NzMrKUxSGJgTtiUCVzSbmW1TmKSg1Y8N7G95\naY+zi5l1vuIkhacfHJkVOTeYWQfLNSlIOlrSAkmLJJ1dZfz7Jd0n6R5Jt0s6KLdY8lpwase+ZwHo\n2eI3ms2sc9VNCpK6JV3Q7IIldQMXA8cABwGnVDnpfy8i5kTES4AvAhc1u57RYlrvMgAmrX+izZGY\nmQ1d3aQQEX3AS9X871keASyKiEciYgtwJXB8xbLXZnqnMEKFL5VPIpmZWaKnwel+D1wr6QfAhtLA\niPjxIPNMBxZn+pcAL6+cSNIHgY8B44E3VFuQpDOBMwH22muvBkM2M7NmNVqnsCuwiuSk/bb079g6\n81S7HN/uTiAiLo6I/YBPAp+utqCI+HpEzI2IudOmTWsw5Nq29G/23YKZWRUN3SlExF8PYdlLgJmZ\n/hnA0hrTQlK89B9DWE/T1vWurT+RmVkBNXSnIGmGpGskPS1puaQfSZpRZ7a7gNmS9pE0HjgZuK5i\nubMzvX8OLGwmeDMza61Gi4++TXJCfwFJXcH16bCaIqIXOAu4EXgIuDoiHpB0vqTj0snOkvSApHtI\n6hVOHcI2mJlZizRa0TwtIrJJ4FJJH6k3U0TcANxQMezcTPeHG1x/x3BbSmbWyRq9U1gp6d3pOwvd\nkt5NUvHc8VreSmqbG1M65LJDuPT+S9sag5l1rkaTwnuBvwSeApYBJ6bDOkbls0atb/todAiCC+df\n2O4wzKxDNfRGM/COiDguIqZFxB4RcUJEPD4C8bXMcHPAqo2rmHPZHK5ddG1L4jEzG40afaP5+HrT\njXWPr01y4I8W/qjNkZiZ5afRiuZfS/oqcBUD32i+O5eozMysLRpNCq9M/z8/Myyo0SxFkfnZIzPr\nZHWTgqQu4D8i4uoRiGfENfoIaeOPmjotmFnnaqROoZ/kJbQxZagVz24zyczGskYfSf25pE9Imilp\n19JfrpFZ08I/OG1mw9RonULpnYQPZoYFsG9rwxm96p1wff9gZmNBo62k7pN3IHkbsWvoNl6tu4kN\nMxuuQYuPJP1DpvukinH/kldQI8klLmZm29SrUzg50/2pinFHtziWEdVsMxelq/Dmf5XUzKxz1EsK\nqtFdrX9Ua1Wwo/npI1c0m9lw1UsKUaO7Wr+ZmXW4ehXNh0paS3KhPSntJu2fmGtkOXuu71nG7Xwn\n8JZ2h2JmNmoMeqcQEd0RsWNETI2InrS71D9upILMww3Lv8DEPa9hybrFDU3fCUUzfvrIzIar0ZfX\nxpyN/WsA6I2+puarV9Hs07KZdbLCJoXWKyULv6dgZp2r8Emh9Q3imZl1rsIkBVXUCQz10dLa8zlp\nmFnnK0xSqKlFFcilpbT1PQbnJTMbpgInheZO3vWKj6JKl5lZpylMUojtnhqK9N8G6xTSO4qadwLp\n8tt5p+B6DzMbrsIkhZapcc4fTSfk0dwUh5mNboVJCpUVzXk13aTRkxvMzJpWnKQwzPmf2fQMAHcu\nu3P4weRkNN2tmFlnyjUpSDpa0gJJiySdXWX8xyQ9KOkPkm6WtHee8VTT6MNHSzcsHXw5LYilVdy8\nt5kNVW5JQVI3cDFwDHAQcIqkgyom+z0wNyIOAX4IfDGveLaLr9kZNq1rbLltPCF3QvtMZja65Xmn\ncASwKCIeiYgtwJXA8dkJIuJXEfFc2nsHMCPHeKpq+DS66dk8w2gpVzSb2VDlmRSmA9kmSJekw2o5\nHfhZtRGSzpQ0T9K8FStWtDDEZjT6noKZWefKMylUu1yteu6U9G5gLnBBtfER8fWImBsRc6dNm9bC\nEBtXr2hmNCQFVzSb2XDV+5Gd4VgCzMz0zwC2q62V9CbgHOB1EbE5x3iGpdHT7WgouhkNMZhZZ8rz\nTuEuYLakfSSNB04GrstOIOkw4D+B4yLi6RxjqanVraS283TsimYzG67ckkJE9AJnATcCDwFXR8QD\nks6XdFw62QXADsAPJN0j6boai8tBs20fmZmNfXkWHxERNwA3VAw7N9P9pjzX34hWXVzHdh1mZp2n\nMG8019aaYqFOygW9/b1cs/Aa+qO/3aGY2SiT653CWFK3vF4D/muvOkFc8eAVXDj/QvqijxMPOHFk\nYjKzjuA7hQY1/vTR6Ld682oA1mxe0+ZIzGy0KUxSqDxZt/qxzW1JY2TTwqk/O5UbH7sxjaEzCrEi\nwk9KmY1ShUkKw9fgy2sjfKtw99N384lbPzFgWN2E1+bz8QnXnsBLr3hpe4Mws6oKX6fQ6ivWTnpP\noV2N9z2y5pG2rNfM6ivunUKTJ8RGm7kYDW8Tj4YYzKwzFSYpDPc0OZZKwDul7sHMRl5hksJw9XfA\nibTZk30zdxSPr32c3y79bbMhmVmHKW6dQpPn+F+tvKexxY6Cp2ryqCs49ppjAbjv1PtavmwzGz0K\ne6cwcWvym8tsWNnQ9Gt7nxt0/GioU2i4cb9RkLjMbHQqbFIY37seAD3XWOOsjZ5IO6mKd7gJbEvf\nFi574DJ6+3tbFJGZtVthk0Kzp8N6V+HbGsQrzlX4N+/7Jl+a9yV+sugn7Q7FzFqksEmh1cpJo03P\n/kPzxULDfQpp3ZZ1ADy3dfCiNTPrHMVJCpN3rTq40RNp3RNoGxrEq9XKab1iodK2dKk4h9/MGlOg\ns8LwTtf9Df9G88ilheUblg9pPjeZbWa1FCgpVNfJzVz0U+NOocEirGHfKfT3ARDp/2bW+QqfFBq1\neuu6doewnaEmtNKdwrCTwtK7k/+fnD+85ZjZqFGYpHBYf6339FpzpxDl/0fu6aPKdTWaJFpWfNS3\nZeD/ZtbxCpMUukdoPSP58tpQ7xRaVdHshvfMxp7CJIVaWnVdX36jeQRfU9juTqHJN5pbd1IvzrsZ\nZmNdYZNCfte47b9T8COpZjZUPis0WL4+ToO3HdiOa+VaTx9t7d86+HytfiS1QG9xm411TgoNOmr3\nQxqabkRL2SvOxUvXLwXqJ4US3ymYWaXinBVqXs02dhrvq3N1va2V1JGz/LmBL689s/mZhuYrFR+5\notjMKhUnKdTU2sc4R/I0e8eyOwb0dzV4OMsVzcNtp6k8v4uPzMaKXJOCpKMlLZC0SNLZVca/VtLd\nknolnZhnLNutu8nTd71mLtqhMlH1RmNNWJfm852CmVXKLSlI6gYuBo4BDgJOkXRQxWRPAKcB38sr\njlrWKjkx9kVjTTTctrqxXxyLETzRVrZOumrjqobmKxcftaxF19GXMM1saPK8UzgCWBQRj0TEFuBK\n4PjsBBHxWET8AWo8RpOjp7uTE9ltq+9tyfLKdQojePF925O3DejffdLuDc3XqvcUVvZvBqDfOcFs\nzMgzKUwHFmf6l6TDmibpTEnzJM1bsWLF0KKZtHPVwb0tasytN31rLUawBdKdJwzcpj0m7wHAXlP3\nGnS+Vr2n8LONSwCYt2nZsJZjZqNHnkmh2mXokK4pI+LrETE3IuZOmzZtaNEcekqtpQ9teRWW9CTt\n/9y2+cGWLK8Rk3smD+gv1SmM6xo36HzlOoUW3daMwuoWMxuiPJPCEmBmpn8GsDTH9Q1u3KSqg3+6\n/PaWrmZl/9qWLm8w7zjgHQP6S7+V3NNV50W7Fjdz0bV55LbZzPKVZ1K4C5gtaR9J44GTgetyXN+Q\nrO3f1NLlPbh1cf2JWqSyYvnmJ24GYMEzCwadr9XNXKivsZflzGz0yy0pREQvcBZwI/AQcHVEPCDp\nfEnHAUh6maQlwEnAf0p6IK94xqKL5l80oP/b93+7ofn8SKqZ1ZLrewoRcUNEHBAR+0XEP6fDzo2I\n69LuuyJiRkRMiYjdIuLgPOOpZc5lc0b18lqt1Y+kyo+kmo0ZfqM5NeeyObzmytcwf/n87V4KW7Ju\nSbl7XIPnvzmXzWHOZXPY3Le5lWHWlG0xdfYusxuadrh3CjtGMv/cBtuFMrPRb/AayYJ5dvOznPY/\npw06zVY1dycw94q5w4yqMYdcvu3EvPCZhfz77/+dncbvxH4778f47vF0q5sudXHvinv5xRO/ABq/\nU8gmnDmXzeFrb/wa++28H7t3T2Rt/0Z2bvD9CDMb/dTqH67P29y5c2PevHlNz3f1gqv57B2fzSEi\nM7ORcfYer+Vdx1w8pHklzY+IulepLj4yM+sQNzzx89zXUcik8OYNz/Gq5za2fLmvy2GZzXjHuvVt\nXb+Z5etDrzgn93UUsk5BEVzy9EoAVp0xj91mDF4xC/DMLz7Da5/8MQD3nbp943gfufL3/OShpXz5\nnYfy9sNm1FxOtrguiO0qe6uV80cEazavYXz3eCaPG/gWc6l+475T74MIfpTWLdx80s30dPXQre7y\n/91d3fSoh5/ccg7nPnE9b+7ehYvefdt266tctyQ4b6dkwPtugz0PHXSeegbEbGajSiGTAsD6iXuy\nQzNt9nR1t2S92ZN+o0//SGLnidXbbqqYsNxZagepmt70iagduyY0tO4BuuvPY2adq5DFR4kmH8cc\nyeZPc9bbmySFnu4hXBP0jG9xNGY2mhQyKbx641Catmj08c0hLHqEle4Ueuo0nFdVt5OC2VhWyOKj\nvbf2gpo8e9dpJ6h1P1jTvF0m7NLU9KXmwns0hMNfp7G9Rpwx5wyWrm9f24hmVlshk0JWNHguV4sa\nj2u1rxz1FQ7c7cCm5in92lz3ULapBfvhw4d/eNjLMLN8FD4pNGyUJoU37v3GpufpTZvxGFpSaE2F\nu5mNTqPzTDeSGq0EGKVJYShiWHcKY6fC3cy2N3bOdE1IWvXM5+mjTqhofvmE5wFw5KQXND9zix7N\nNbPRqZDFR8npvdmz9+BJoZOunw+fsBv3PvoEXbOe3/zMY+iOycy25294o8UhY+lkGP3JgR9KUZDr\nFMzGtDF0phvcjB1qND3R6A1DB90KHLN+w+ATpI+kDinRjaXkaGbbKUzx0Sunv7LcPXvLVii11tBw\nJUBnnAznP/oEda/l574XHryAWDHUAAAOzElEQVQWDj2l+RW4TsFsTCtMUoCkIbyQmBhB0+80N1rR\n3HRUrdXQ+8a77A0fvmdoK/CdgtmYVshv+ICG6Bo82dd9ea2DipeGxUnBbEwr5jd8SCe2opz16/B7\nCmZjWmGTQn9al9BwcY+vkM2sAIp5ppNYsDH50Zg7H1/X2DxTk2f6ezrh7TQzsyEqVEXz5Ag2SKAu\nztzyUV7VdT9z+nZqbOY9kkbnuuvkhHDSMLMOVqik8L2lT/HrSZPoUher2ZHr+1/J/lv6m1pGrVur\nRn9FzcxsNCtUUth3ay/7bl0H46Ywrlts7Qs29fY1NG+pDmJ8jVqIaPvDqGZmw1fMOoVdZrHL5OSJ\n/hvvf6qhWbb0bwFgQo0fYNjalySF3v72JYe+Nq7bzMaGXJOCpKMlLZC0SNLZVcZPkHRVOv5OSbPy\njIf93pD8P/1wnr/TRAAeWbmBWWf/N7PO/m9++cfltesE+pNiphf1Vh9//b3JL4n9280LWxtzHVv7\n+ssxr96wJb8VHX4qjJuS3/LNbFTIrfhIUjdwMfBmYAlwl6TrIuLBzGSnA89ExP6STga+ALwzr5g4\n7N3wp1/C5N046oV78IclawaMfu+l88rds/fYgV2mjGfHiePY0tfPs4sf4r8mLGfHjTvymWvvZ+rE\ncUwa382Eni56urbdPSxbs4lZZ/83u00Zz967TWbnyeOZOrGHHSb0MGVCD5PGdTNxXDfje7oY39PF\nuC7R050so7tL9HSJri7RJdHdBV3Str+0v7tLTJ3Yw5TxPbzmi7/iRc+fyjdPncvSZzfxxa1nck//\n/rzt5oX0dIvx3V2M6+6ip1uM6+5ifHcX3V1i+dpNHPC8qXRJSMnrB9vWlfy8aJegp6uLnSeP4+qJ\nH+SXU0/ioqeSp7W6u6A/4Lt3PM7xh01nfHdXshy2xbltOaJbYuK4LnacNI5bFjzNgqfW88YD9wAo\nz1eKo9xN6bWIbL/Kw0vTlZdRY1yyBLbrydYD1Zq29DOrA4dlpy0vbDvVXumodp9Z66dca9VSVV9u\njWW0sKqrkWXVq1urt4zBRtf7yduhbmqtxbbzJ3bbSXk9LSPpSOC8iHhL2v8pgIj4XGaaG9Npfiup\nB3gKmBaDBDV37tyYN29erdGD6++H+d+Gl7yL/u4JrFy/mT12nMi6TVuZc95NAIzv7mK3HcbTJbFx\nax+bt/axpa+fSX3r+MPEM/nM1lO5uuutbNw6eF3EHlMnMH2XSWza2s/6zVvZsLmPDZt72dzbXMW2\nmY19jeaffzrhxbzr5XsPcR2aHxFz602XZ0XzdGBxpn8J8PJa00REr6Q1wG7AyuxEks4EzgTYa6+9\nhh5RVxe87PSkE9hjx6QIaerEcTz2+T8fdNZ1m7Yy67wpzP/0m/nHHSbQ1x88t6WXrX1Bb38/BBzx\nLzcD8Ojn3lrzKqO/P9jc28/m3iTZ9PZF8tffT19/0Nsf9PUHEdAXQX8E/f1BfyR1BkEyft2mXhYu\nX8+Xf/Ewp71yFgfuOZWf3f8UtyxYwYJ/Opqeri629vWnfzGg+7ktvdz0wHJePXv3ckyR/T+2xdDb\nHzz73BZ++8gq1m7cytsPS1qb7Ytk+M8fXM5fHTmLiGTeiCTWiGQ55b9+2Li1jzUbt3LBjQsA+Pp7\nXprOA5Csr9QfA/rTFw2zwzPj0tkr5tm2z7MPAZSGD7jqyEwcVQZHvfFVjnOjF1u1Jqv14EK16Wut\nqdHrvUYekmjFtWO9fTLY6HqrH2p8zeznxpY3lJkan+vgFzT4CP0w5HmncBLwlog4I+1/D3BERPxd\nZpoH0mmWpP1/SqdZVWu5w7pTMDMrqEbvFPKsaF4CzMz0zwCW1pomLT7aCVidY0xmZjaIPJPCXcBs\nSftIGg+cDFxXMc11wKlp94nALwerTzAzs3zlVqeQ1hGcBdwIdAPfiogHJJ0PzIuI64D/Ar4jaRHJ\nHcLJecVjZmb15fpGc0TcANxQMezcTPcm4KQ8YzAzs8YV841mMzOryknBzMzKnBTMzKzMScHMzMpy\ne3ktL5JWAI8PcfbdqXhbepRwXM1xXM0brbE5ruYMJ669I2JavYk6LikMh6R5jbzRN9IcV3McV/NG\na2yOqzkjEZeLj8zMrMxJwczMyoqWFL7e7gBqcFzNcVzNG62xOa7m5B5XoeoUzMxscEW7UzAzs0E4\nKZiZWVlhkoKkoyUtkLRI0tk5r2umpF9JekjSA5I+nA4/T9KTku5J/96amedTaWwLJL0lz7glPSbp\nvjSGeemwXSX9XNLC9P9d0uGS9G/p+v8g6fDMck5Np18o6dRa62swphdm9ss9ktZK+kg79pmkb0l6\nWtL9mWEt2z+SXpru/0XpvA39GGONuC6Q9Md03ddI2jkdPkvSxsx+u6Te+mtt4xDjatlxU9L8/p1p\nXFcpaYp/qHFdlYnpMUn3tGF/1To/tP0zBqQ/ZzjG/0ia7v4TsC8wHrgXOCjH9e0JHJ52TwUeBg4C\nzgM+UWX6g9KYJgD7pLF25xU38Biwe8WwLwJnp91nA19Iu98K/Izkd9FfAdyZDt8VeCT9f5e0e5cW\nHq+ngL3bsc+A1wKHA/fnsX+A3wFHpvP8DDhmGHH9GdCTdn8hE9es7HQVy6m6/lrbOMS4WnbcgKuB\nk9PuS4APDDWuivEXAue2YX/VOj+0/TMWEYW5UzgCWBQRj0TEFuBK4Pi8VhYRyyLi7rR7HfAQye9R\n13I8cGVEbI6IR4FFacwjGffxwGVp92XACZnhl0fiDmBnSXsCbwF+HhGrI+IZ4OfA0S2K5Y3AnyJi\nsDfXc9tnEXEb2/8CYEv2Tzpux4j4bSTf3sszy2o6roi4KSJ60947SH7hsKY666+1jU3HNYimjlt6\nhfsG4IetjCtd7l8C3x9sGTntr1rnh7Z/xqA4xUfTgcWZ/iUMfpJuGUmzgMOAO9NBZ6W3gN/K3G7W\nii+vuAO4SdJ8SWemw54XEcsg+dACe7QpNkh+bCn7ZR0N+6xV+2d62t3q+ADeS3JVWLKPpN9LulXS\nazLx1lp/rW0cqlYct92AZzOJr1X76zXA8ohYmBk24vur4vwwKj5jRUkK1crTcn8WV9IOwI+Aj0TE\nWuA/gP2AlwDLSG5fB4svr7hfFRGHA8cAH5T02kGmHdHY0vLi44AfpINGyz6rpdk48tpv5wC9wHfT\nQcuAvSLiMOBjwPck7ZjX+qto1XHLK95TGHjhMeL7q8r5oeakNWLIZZ8VJSksAWZm+mcAS/NcoaRx\nJAf8uxHxY4CIWB4RfRHRD3yD5JZ5sPhyiTsilqb/Pw1ck8axPL3tLN0yP92O2EgS1d0RsTyNcVTs\nM1q3f5YwsIhn2PGlFYzHAu9KiwtIi2dWpd3zScrrD6iz/lrb2LQWHreVJMUlPRXDhyxd1l8AV2Xi\nHdH9Ve38MMjyRvYz1mjlQyf/kfzs6CMkFVulSqyDc1yfSMrxvlIxfM9M90dJylYBDmZg5dsjJBVv\nLY8bmAJMzXT/hqQu4AIGVnJ9Me3+cwZWcv0utlVyPUpSwbVL2r1rC/bdlcBft3ufUVHx2Mr9A9yV\nTluqBHzrMOI6GngQmFYx3TSgO+3eF3iy3vprbeMQ42rZcSO5a8xWNP/tUOPK7LNb27W/qH1+GB2f\nseF+iTvlj6QG/2GSK4Bzcl7Xq0lu1/4A3JP+vRX4DnBfOvy6ii/OOWlsC8g8KdDquNMP/L3p3wOl\nZZKU3d4MLEz/L324BFycrv8+YG5mWe8lqShcROZEPozYJgOrgJ0yw0Z8n5EUKywDtpJcdZ3eyv0D\nzAXuT+f5KmnLAkOMaxFJuXLpc3ZJOu070uN7L3A38LZ666+1jUOMq2XHLf3M/i7d1h8AE4YaVzr8\nUuD9FdOO5P6qdX5o+2csItzMhZmZbVOUOgUzM2uAk4KZmZU5KZiZWZmTgpmZlTkpmJlZmZOCjXqS\nQtKFmf5PSDqvRcu+VNKJrVhWnfWclLaK+auK4ZWtc94j6a9auN6jJP20Vcuzsa+n/iRmbbcZ+AtJ\nn4uIle0OpkRSd0T0NTj56SQvXf2qyrg/RcRLWhia2ZD5TsE6QS/Jb9N+tHJE5ZW+pPXp/0elDZtd\nLelhSZ+X9C5Jv0vbmd8vs5g3SfrfdLpj0/m7lfxWwV1po27vyyz3V5K+R/IiUWU8p6TLv1/SF9Jh\n55K8sHSJpAsa3WhJ6yVdKOluSTdLmpYOf4mkO7TtNxRK7e7vL+kXku5N5ylt4w6Sfqjkdxe+21Tb\n+lY4TgrWKS4G3iVppybmORT4MDAHeA9wQEQcAXwT+LvMdLOA15E0J3CJpIkkV/ZrIuJlwMuAv5G0\nTzr9ESRv3B6UXZmkF5D8psEbSBqCe5mkEyLifGAeSdtEf18lzv0qio9KLXROIWkH6nDgVuAz6fDL\ngU9GxCEkiak0/LvAxRFxKPBKkrd5IWmF8yMkbfbvC7yqgX1nBeXiI+sIEbFW0uXAh4CNDc52V6RN\nEUv6E3BTOvw+4PWZ6a6OpOG2hZIeAV5E8uM1h2TuQnYCZgNbSNqeebTK+l4G3BIRK9J1fpfkh15+\nUifOWsVH/WxrtO0K4MdpUtw5Im5Nh18G/EDSVGB6RFwDEBGb0hhI412S9t9DkgRvrxOTFZSTgnWS\nr5C0S/PtzLBe0jvetFgk+1ONmzPd/Zn+fgZ+9ivbeik1P/x3EXFjdoSko4ANNeLLu1hmsDZpBlt3\ndj/04e+9DcLFR9YxImI1yU8znp4Z/Bjw0rT7eGDcEBZ9kqSutAx+X5KG2m4EPpA2cYykAyRNqbOc\nO4HXSdpdUjdJm/231plnMF1A6U7l/wC3R8Qa4JlMEdN7SFr8XAsskXRCGu8ESZOHsW4rKF8xWKe5\nEDgr0/8N4FpJvyNpWbLWVfxgFpCcvJ9H0nrmJknfJClmuTu9A1lBnZ80jIhlkj4F/Irkyv2GiLi2\ngfXvlxbrlHwrIv6NZFsOljQfWAO8Mx1/Kkndx2SS5qb/Oh3+HuA/JZ1P0jLoSQ2s22wAt5JqNkpJ\nWh8RO7Q7DisWFx+ZmVmZ7xTMzKzMdwpmZlbmpGBmZmVOCmZmVuakYGZmZU4KZmZW9v8BXuOWOxEc\nSdIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x4e81f3a7f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "inst = NeuralNet(x_train, y_train, x_test, y_test)\n",
    "\n",
    "def main():\n",
    "    trmse = inst.train_nn()\n",
    "    inst.predictClass()\n",
    "    plt.plot(trmse)\n",
    "    plt.xlabel(\"Number of Epoch\")\n",
    "    plt.ylabel(\"Error\")\n",
    "    plt.title(\"Error vs Epoch - Gradient Descent (Training Phase)\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    #ax=plt.axes()\n",
    "    #arr = metrics.confusion_matrix(inst.y_test, inst.test_pred, sample_weight=None)\n",
    "    #con_df = pd.DataFrame(arr, columns = [\"Predicted_0\", \"Predicted_1\"], index=[\"Actual_0\", \"Actual_1\"])\n",
    "    #sns.heatmap(con_df, annot=True,annot_kws={\"size\": 8}, fmt='g', cmap='Blues', ax=ax)\n",
    "    #ax.set_title('Confusion Matrix - Test Phase')\n",
    "    #plt.show()\n",
    "    #print('Test Accuracy: ', 1-np.sum(abs(inst.test_pred - inst.y_test))/inst.y_test.shape[0])\n",
    "    #x = inst.sig[0].tolist()\n",
    "    #y = inst.zvalue[0].tolist()\n",
    "   \n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 0.,  1.,  0.]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inst.test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [0, 1, 0],\n",
       "       [1, 0, 0],\n",
       "       [0, 0, 1],\n",
       "       [1, 0, 0],\n",
       "       [0, 0, 1],\n",
       "       [0, 1, 0],\n",
       "       [1, 0, 0],\n",
       "       [0, 1, 0],\n",
       "       [1, 0, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 0, 1],\n",
       "       [0, 1, 0],\n",
       "       [1, 0, 0],\n",
       "       [0, 0, 1],\n",
       "       [0, 1, 0],\n",
       "       [0, 0, 1],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 0, 1],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 0, 1],\n",
       "       [0, 1, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 0, 1],\n",
       "       [1, 0, 0],\n",
       "       [0, 0, 1]], dtype=uint8)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 0.,  1.,  0.],\n",
       "       [ 1.,  0.,  0.],\n",
       "       [ 0.,  1.,  0.]])"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inst.test_pred"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
